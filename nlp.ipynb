{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Strings Data in NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red', 'yellow', 'green', 'brown']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This is a string data from a fixed number of list \n",
    "    This can be a drop-down menu for the user to select from \n",
    "\"\"\"\n",
    "categorical_data = [\"red\", \"yellow\", \"green\", \"brown\"]\n",
    "\n",
    "print(categorical_data) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Free strings that can be semantically mapped to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This is when the user is allowed to type/color a color without a fixed list (draw-down menu) provided. \\n    The result can still be mapped as mapped as a categorical data. \\n    One must however check for spelling mistates as they might mean the same thing\\n    like February and Februry \\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" This is when the user is allowed to type/color a color without a fixed list (draw-down menu) provided. \n",
    "    The result can still be mapped as mapped as a categorical data. \n",
    "    One must however check for spelling mistates as they might mean the same thing\n",
    "    like February and Februry \n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Structured String Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This is the form of data with no specific structure \\n    For example, blog message, twitter comment, youtube comment, etc\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" This is the form of data with no specific structure \n",
    "    For example, blog message, twitter comment, youtube comment, etc\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the IMDB Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "data_imdb = pd.read_csv('data/imdb_dataset.csv')\n",
    "print(data_imdb.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(data_imdb.sentiment.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to remove break line from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_preprocess(data):\n",
    "    return data.replace('<br /><br />', \" \")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          new_review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production.  The filming te...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "data_imdb[\"new_review\"] = data_imdb[\"review\"].apply(lambda x : first_preprocess(x))\n",
    "process_data = data_imdb[[\"new_review\", \"sentiment\"]]\n",
    "print(process_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_imdb[\"new_review\"], data_imdb[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = [i for i in X]\n",
    "y_ = [i for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "33500 16500 33500 16500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(type(X_train))\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "33500 16500 33500 16500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.33, random_state=42)\n",
    "\n",
    "print(type(X_train))\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randolph Scott is heading into Albuquerque to take a job with his uncle. However, on the way there, the stage is held up--even though they are not carrying a strongbox. However, a nice lady on board is concealing $10,000 for her and her brother's business...and the robbers seem to know this. Once in town, Scott goes to this uncle about the job. However, he soon learns that this uncle is a jerk--the typical bad guy from Westerns. You know, the rich guy who only wants to become richer by cheating and stealing and threatening until he owns everything. And, it just so happens that this jerk was behind the robbery. Scott demands that the uncle returns the money and then Scott goes into business with the nice lady and her brother. Not surprisingly, this is NOT the end of the problems---just the beginning. Again and again, intrigues of various types occur to try to crush the uncle's opposition. One trick is to bring in a pretty lady to befriend Scott and his partners. She's a crack shot and it looks bad for Scott--until he figures out why she's come to town. Unlike most later Randolph Scott films, this one shows Scott as a bit more headstrong man. All too often in his films he's the last one to suggest violence, but in this film he's quick to suggest a lynching (screw the law, let's have a hangin') and later he's quick to threaten the uncle. What a surprise to see him as such a hot-head--though in most other ways, he's the same old Scott you'd expect. As far as the film goes, there's nothing particularly unusual about it. Gabby Hayes plays the usual character, Scott is a hero, the baddie cannot be reasoned with and ultimately is destroyed and Scott gets the girl. Despite this very typical plot, it's all handled very well and as a result is well worth your time. By the way, there are two weird scenes in the film. First, late in the movie, there is a fist fight between Scott and the uncle's #1 henchman, Lon Chaney, Jr.. In it, Chaney smokes as he fights--something I never saw before and I did admire how he could puff away as he got his butt kicked. Second, get a load of that runaway cart scene with the whip--now THAT was one impossible feat!\n",
      "positive\n",
      "I like this movie cause it has a good approach of Buddhism, for example, the way Buddhist use to care all kind of living things, combining some fancy and real situations; in some parts the photography is very good and a lot of messages about freedom, as the hawk episode, staying always focused in every moment, even in tough situations.. It has also funny situations as Swank's birthday and, talking this two times academy awards, her acting show us how the people who use to live in this kind of culture is trying to have a resistance behavior when Miyagi is taking her to a Buddhist temple, and how she, slowly, is changing her mind. And, of course, Pat Morita has been always great\n",
      "positive\n",
      "Well don't expect anything deep an meaningful. Most of the fight scenes are pretty decent. The two leading ladies are quite endearing but their lack of HK action background shows at times. The ending maybe lacks something but I quite enjoyed it none the less. The cheesy humour isn't probably going to appeal to anyone who hasn't watched a bunch of HK films but if your down with that sort of thing and have a couple of hours to fill with something meaningless you could do a lot worse than this. (OK so you could do better but.......) Certainly on a par with most of the Hollywood blockbuster action drivel. 7/10\n",
      "positive\n",
      "This really should deserve a \"O\" rating, or even a negative ten. I watched this show for ages, and the show jumped the shark around series 7. This episode, however, is proof that the show has jumped the shark. It's writing is lazy, absurd, self-indulgent and not even worthy of rubbish like Beavis and Butthead. It is quite possible to be ridiculous and still be fun -- Pirates of the Caribbean, the Mummy, Count of Monte Cristo -- all \"fun\" movies that are not to be taken seriously. However, there is such thing as ridiculous as in \"this is the worst thing I've ever seen.\" And indeed, this is the worst episode of Stargate I've ever seen. It's absolutely dreadful, and this coming from someone with a stargate in her basement. Makes me want to sell all of my stargate props, most seriously.\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(X_train[i])\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "33500 16500 33500 16500\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Data as BAG OF WORDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vocabulary Building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Bag-of-Words to a Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 13\n",
      "\n",
      "Vocabulary content: \n",
      "{'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
     ]
    }
   ],
   "source": [
    "bards_words = [\"The fool doth think he is wise\", \"but the wise man knows himself to be a fool\"]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vect.vocabulary_)}\\n\")\n",
    "print(f\"Vocabulary content: \\n{(vect.vocabulary_)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : <2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "print(f\"bag of words : {repr(bag_of_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : \n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 12)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 12)\t1\n"
     ]
    }
   ],
   "source": [
    "print(f\"bag of words : \\n{(bag_of_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : \n",
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"bag of words : \\n{(bag_of_words.toarray())}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the Bag-of-Words to the IMDB Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: \n",
      "<33500x86358 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 4541135 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: \\n{repr(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features : 86358\n",
      "\n",
      "First 20 features : \n",
      "----------------------------------------------------------------------\n",
      "['00' '000' '00000000000' '00000001' '00001' '000dm' '000s' '001' '003830'\n",
      " '007' '0079' '0080' '0083' '009' '0093638' '00am' '00o' '00pm' '00s'\n",
      " '00schneider']\n",
      "\n",
      "Feature 2000th - 2020th features : \n",
      "----------------------------------------------------------------------\n",
      "['adarsh' 'adas' 'aday' 'adays' 'add' 'addam' 'addams' 'addario' 'added'\n",
      " 'addendum' 'adder' 'addict' 'addicted' 'addicted2you' 'addicting'\n",
      " 'addiction' 'addictions' 'addictive' 'addicts' 'addie']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "print(f\"Number of features : {len(feature_names)}\\n\")\n",
    "print(f\"First 20 features : \\n{'-'*70}\\n{feature_names[:20]}\\n\")\n",
    "print(f\"Feature 2000th - 2020th features : \\n{'-'*70}\\n{feature_names[2000:2020]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first set of features are actually not words but numeric numbers which has the form of a string. We have to eliminate all those features as the have no semantic significance. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before Let's train the model and check the accuracy first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model    import LogisticRegression \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy :  0.88\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean cross-validation accuracy :  {np.mean(scores) :.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\" : [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score : 0.890\n",
      "Best parameters : {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best cross-validation score : {grid.best_score_:.3f}\")\n",
    "print(f\"Best parameters : {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.898\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test score: {grid.score(X_test, y_test) :.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
